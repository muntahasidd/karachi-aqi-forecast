# -*- coding: utf-8 -*-
"""pipeline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UBRqlC3wmC1PddzxynRfRzRIF9WDw65O
"""

import requests
import pandas as pd
import datetime
import pickle
import hopsworks

#  FETCH WEATHER + PM DATA
API_KEY = "6094f98aa9ad646bfcbdd49788573e5b"
LAT, LON = 24.8607, 67.0011

# --- Weather Forecast ---
weather_url = f"https://api.openweathermap.org/data/2.5/forecast?lat={LAT}&lon={LON}&appid={API_KEY}&units=metric"
weather_res = requests.get(weather_url).json()

weather_records = []
for entry in weather_res['list']:
    ts = datetime.datetime.fromtimestamp(entry['dt'])
    weather_records.append({
        "timestamp": ts,
        "temperature": entry['main']['temp'],
        "humidity": entry['main']['humidity'],
        "wind_speed": entry['wind']['speed'],
        "hour": ts.hour,
        "day": ts.day,
        "month": ts.month
    })
df_weather = pd.DataFrame(weather_records)

#  Air Pollution (PM2.5, PM10)
pm_records = []
for ts in df_weather['timestamp']:
    unix_ts = int(ts.timestamp())
    air_url = f"http://api.openweathermap.org/data/2.5/air_pollution/history?lat={LAT}&lon={LON}&start={unix_ts}&end={unix_ts}&appid={API_KEY}"
    air_res = requests.get(air_url).json()

    if air_res.get('list'):
        pm2_5 = air_res['list'][0]['components']['pm2_5']
        pm10  = air_res['list'][0]['components']['pm10']
    else:
        pm2_5, pm10 = 0, 0

    pm_records.append({"timestamp": ts, "pm2_5": pm2_5, "pm10": pm10})

df_pm = pd.DataFrame(pm_records)

# Merge Weather + PM Data
df_forecast = pd.merge(df_weather, df_pm, on="timestamp")
df_forecast.reset_index(drop=True, inplace=True)

# LOAD SCALER & MODEL
with open("scaler.pkl", "rb") as f:
    scaler = pickle.load(f)

with open("best_model.pkl", "rb") as f:
    rf_model = pickle.load(f)

#  SCALE FEATURES
feature_cols = ['pm2_5','pm10','temperature','humidity','wind_speed','hour','day','month']
df_forecast_scaled = df_forecast.copy()
df_forecast_scaled[feature_cols] = scaler.transform(df_forecast_scaled[feature_cols])

#
df_forecast["predicted_aqi"] = rf_model.predict(df_forecast_scaled[feature_cols])

#  LOGIN TO HOPSWORKS
project = hopsworks.login()
fs = project.get_feature_store()

# UPLOAD PREDICTIONS
forecast_fg = fs.get_or_create_feature_group(
    name="karachi_aqi_forecast",
    version=1,
    description="Predicted AQI for Karachi 5-day forecast",
    primary_key=["id"],
    online_enabled=False
)

df_hf = df_forecast.copy()
df_hf.reset_index(inplace=True)
df_hf.rename(columns={"index": "id"}, inplace=True)

forecast_fg.insert(df_hf, write_options={"wait_for_job": True})
print(" AQI predictions uploaded to HopsWorks Feature Group!")

#  7 UPLOAD MODEL & SCALER
# Use HopsWorks model registry
mr = project.get_model_registry()

# Upload Random Forest model
rf_model_entity = mr.python.create_model(
    name="rf_aqi_model",
    metrics={},
    description="Random Forest model for AQI prediction"
)
rf_model_entity.save("best_model.pkl")
print("✅ Random Forest model uploaded to HopsWorks Model Registry!")

# Upload Scaler
scaler_entity = mr.python.create_model(
    name="scaler_aqi",
    metrics={},
    description="Scaler used for AQI prediction"
)
scaler_entity.save("scaler.pkl")
print("✅ Scaler uploaded to HopsWorks Model Registry!")

# ---------------- 8️⃣ SHOW SAMPLE ----------------
print(df_forecast[["timestamp", "predicted_aqi"]].head())
