# -*- coding: utf-8 -*-
"""Untitled32.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rra5ROMsO_tOXG9YhZQhENSATE0FTL7c
"""

import pandas as pd
import numpy as np

df=pd.read_csv('karachiiii.csv')

df.head()

df.info

df.describe()

before = len(df)
df = df.drop_duplicates()
after = len(df)
print(f"Removed {before-after} duplicate timestamps")

null_counts = df.isna().sum().sort_values(ascending=False)
print(null_counts)

import seaborn as sns
import matplotlib.pyplot as plt

pollutants = ['aqi','pm2_5','pm10']

plt.figure(figsize=(5,4))
sns.boxplot(data=df[pollutants])
plt.title("Boxplots for AQI and Pollutants")
plt.xticks(rotation=45)
plt.show()

df['aqi'].value_counts().head()

df[df['pm2_5'] > 600][['pm2_5']].head()

df['hour'] = pd.to_datetime(df['timestamp']).dt.hour
df['day'] = pd.to_datetime(df['timestamp']).dt.day
df['month'] = pd.to_datetime(df['timestamp']).dt.month
df['aqi_change'] = df['aqi'].diff().fillna(0)

df.head()

num_cols = ['temperature', 'humidity', 'wind_speed', 'pm2_5', 'pm10', 'aqi',"aqi_change","month","day","hour"]

outlier_indices = {}
for col in num_cols:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
    outlier_indices[col] = len(outliers)

    print(f"{col}: {len(outliers)} outliers")

def cap_outliers(df, cols):
    capped_df = df.copy()

    for col in cols:

        Q1 = capped_df[col].quantile(0.25)
        Q3 = capped_df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower = Q1 - 1.5 * IQR
        upper = Q3 + 1.5 * IQR

        capped_df[col] = np.where(
            capped_df[col] < lower, lower,
            np.where(capped_df[col] > upper, upper, capped_df[col])
        )


    return capped_df

import matplotlib.pyplot as plt

for col in ['temperature','wind_speed','pm2_5','pm10']:
    plt.figure(figsize=(5,4))
    df[col].plot()
    plt.title(f"{col} over time")
    plt.show()

numeric_cols = [
    "temperature", "humidity", "wind_speed", "pm2_5", "pm10", "aqi"
]

df = cap_outliers(df, numeric_cols)

print("\nAfter capping:")
print(df[numeric_cols].describe())

df.head()

X=df.drop(columns=["timestamp","aqi"])
y=df["aqi"]

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
num_cols=['pm2_5','pm10','temperature','humidity','wind_speed','hour','day','month','aqi_change']
scaler=StandardScaler()
X[num_cols]=scaler.fit_transform(X[num_cols])

import joblib
joblib.dump(scaler,'scaler.pkl')

print(X.head())

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import numpy as np

# Train Random Forest
rf = RandomForestRegressor(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# Predictions
y_pred_rf = rf.predict(X_test)

# Evaluation
r2 = r2_score(y_test, y_pred_rf)
mae = mean_absolute_error(y_test, y_pred_rf)
rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf))
acc = (1 - (mae / np.mean(y_test))) * 100

print("ðŸ“Š Random Forest Regressor Results:")
print(f"RÂ² Score: {r2:.3f}")
print(f"Mean Absolute Error: {mae:.3f}")
print(f"Root Mean Squared Error: {rmse:.3f}")
print(f"Approx Accuracy: {acc:.2f}% ")

# Check how model performs on training data too
y_train_pred = rf.predict(X_train)
y_test_pred = rf.predict(X_test)

train_r2 = r2_score(y_train, y_train_pred)
test_r2 = r2_score(y_test, y_test_pred)

print("ðŸŒ² Random Forest Sanity Check:")
print(f"Train RÂ²: {train_r2:.4f}")
print(f"Test RÂ²:  {test_r2:.4f}")

if abs(train_r2 - test_r2) < 0.02:
    print(" Perfectly balanced â€” not overfitting!")
elif abs(train_r2 - test_r2) < 0.05:
    print(" Slight overfitting, but acceptable.")
else:
    print(" Overfitting detected! Try regularization or tuning.")

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import numpy as np




X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Train Linear Regression
lr = LinearRegression()
lr.fit(X_train, y_train)

# Predictions
y_pred = lr.predict(X_test)

# Evaluation
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
acc = (1 - (mae / np.mean(y_test))) * 100

print(" Linear Regression Results:")
print(f"RÂ² Score: {r2:.3f}")
print(f"Mean Absolute Error: {mae:.3f}")
print(f"Root Mean Squared Error: {rmse:.3f}")
print(f"Approx Accuracy: {acc:.2f}% ")

import pandas as pd
import matplotlib.pyplot as plt

# Get feature importance (absolute value of coefficients)
importance = pd.Series(lr.coef_, index=X.columns).sort_values(ascending=False)

# Plot
plt.figure(figsize=(8,5))
importance.plot(kind='bar', color='skyblue')
plt.title("Feature Importance - Linear Regression Model")
plt.ylabel("Coefficient Magnitude")
plt.xlabel("Feature")
plt.show()

# Print table
print("\nðŸ”¹ Linear Regression Coefficients:")
print(importance)

from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import numpy as np

# Train KNN Regressor
knn = KNeighborsRegressor(n_neighbors=5)
knn.fit(X_train, y_train)

# Predictions
y_pred_knn = knn.predict(X_test)

# Evaluation
r2 = r2_score(y_test, y_pred_knn)
mae = mean_absolute_error(y_test, y_pred_knn)
rmse = np.sqrt(mean_squared_error(y_test, y_pred_knn))
acc = (1 - (mae / np.mean(y_test))) * 100

print(" KNN Regressor Results:")
print(f"R Score: {r2:.3f}")
print(f"Mean Absolute Error: {mae:.3f}")
print(f"Root Mean Squared Error: {rmse:.3f}")
print(f"Approx Accuracy: {acc:.2f}% ")

from sklearn.inspection import permutation_importance

result = permutation_importance(knn, X_test, y_test, n_repeats=10, random_state=42)
importance_knn = pd.Series(result.importances_mean, index=X.columns).sort_values(ascending=False)

# Plot
plt.figure(figsize=(8,5))
importance_knn.plot(kind='bar', color='orange')
plt.title("Feature Importance - KNN Regressor")
plt.ylabel("Importance Score")
plt.xlabel("Feature")
plt.show()

# Print table
print("\nðŸ”¸ KNN Feature Importance (Permutation):")
print(importance_knn)

from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import numpy as np

models = {"Random Forest": rf, "Linear Regression": lr, "KNN": knn}

for name, model in models.items():
    y_pred = model.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))

    print(f"--- {name} ---")
    print(f"RÂ² Score: {r2:.4f}")
    print(f"MAE: {mae:.4f}")
    print(f"RMSE: {rmse:.4f}\n")

import joblib
# Save Random Forest
joblib.dump(rf, "random_forest_aqi.pkl")

# Save Linear Regression
joblib.dump(lr, "linear_regression_aqi.pkl")

# Save KNN
joblib.dump(knn, "knn_aqi.pkl")

print("âœ… All models saved successfully!")

import requests
import pandas as pd
import datetime
API_KEY = "6094f98aa9ad646bfcbdd49788573e5b"  # replace with your OpenWeatherMap API key
LAT, LON = 24.8607, 67.0011  # Karachi coordinates

weather_url = f"https://api.openweathermap.org/data/2.5/forecast?lat={LAT}&lon={LON}&appid={API_KEY}&units=metric"
weather_res = requests.get(weather_url).json()

# Extract weather data
weather_records = []
for entry in weather_res['list']:
    ts = datetime.datetime.fromtimestamp(entry['dt'])
    temp = entry['main']['temp']
    humidity = entry['main']['humidity']
    wind_speed = entry['wind']['speed']

    weather_records.append({
        "timestamp": ts,
        "temperature": temp,
        "humidity": humidity,
        "wind_speed": wind_speed,
        "hour": ts.hour,
        "day": ts.day,
        "month": ts.month
    })

df_weather = pd.DataFrame(weather_records)
print(f"âœ… Weather forecast records fetched: {len(df_weather)}")

pm_records = []

for ts in df_weather['timestamp']:
    # Convert timestamp to Unix (seconds)
    unix_ts = int(ts.timestamp())

    air_url = f"http://api.openweathermap.org/data/2.5/air_pollution/history?lat={LAT}&lon={LON}&start={unix_ts}&end={unix_ts}&appid={API_KEY}"
    air_res = requests.get(air_url).json()

    # Some timestamps may not have data
    if air_res.get('list'):
        pm2_5 = air_res['list'][0]['components']['pm2_5']
        pm10  = air_res['list'][0]['components']['pm10']
    else:
        pm2_5, pm10 = None, None

    pm_records.append({"timestamp": ts, "pm2_5": pm2_5, "pm10": pm10})

df_pm = pd.DataFrame(pm_records)

df_forecast = pd.merge(df_weather, df_pm, on='timestamp')
print(df_forecast.head())

df_forecast['pm2_5'].fillna(method='ffill', inplace=True)
df_forecast['pm10'].fillna(method='ffill', inplace=True)

df_forecast['aqi_change'] = 0  # for future prediction

df_forecast.columns

timestamps=df_forecast['timestamp']

df_features=df_forecast[num_cols]

import joblib
scaler=joblib.load('scaler.pkl')
df_scaled=pd.DataFrame(scaler.transform(df_features),columns=df_features.columns)

model=joblib.load('random_forest_aqi.pkl')
df_forecast['aqi']=model.predict(df_scaled)

df_forecast['timestamp']=timestamps

print(df_forecast[['timestamp','aqi']].head(10))

df_forecast.to_csv('future_karachi_aqi.csv',index=False)